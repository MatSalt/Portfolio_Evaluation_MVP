"""
Gemini API ì—°ë™ ì„œë¹„ìŠ¤ - ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ ì¶œë ¥

ì´ ëª¨ë“ˆì€ Google Gemini 2.5 Flash APIë¥¼ ì‚¬ìš©í•˜ì—¬ í¬íŠ¸í´ë¦¬ì˜¤ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³ 
expected_result.mdì™€ ë™ì¼í•œ í˜•ì‹ì˜ ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""

import os
import asyncio
import base64
import hashlib
from typing import Optional, Dict, List, Union
from io import BytesIO
import logging
import uuid
import time
from google import genai
from google.genai.types import GenerateContentConfig, Part

from models.portfolio import AnalysisResponse, SAMPLE_MARKDOWN_CONTENT, StructuredAnalysisResponse, PortfolioReport
from utils.image_utils import validate_image, optimize_image

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

class GeminiService:
    """Gemini API ì—°ë™ ì„œë¹„ìŠ¤ - ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ ì¶œë ¥"""
    
    def __init__(self):
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.api_key = os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            raise ValueError("GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.client = genai.Client(api_key=self.api_key)
        
        # ì„¤ì •ê°’
        self.model_name = os.getenv("GEMINI_MODEL", "gemini-2.5-flash")
        self.timeout = int(os.getenv("GEMINI_TIMEOUT", "600"))  # Two-step ì „ëµ í†µí•© íƒ€ì„ì•„ì›ƒ (10ë¶„)
        self.max_retries = int(os.getenv("GEMINI_MAX_RETRIES", "3"))
        
        # ìºì‹œ ë”•ì…”ë„ˆë¦¬ (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” Redis ë“± ì‚¬ìš©)
        self._cache: Dict[str, str] = {}
        
        logger.info(f"GeminiService ì´ˆê¸°í™” ì™„ë£Œ - ëª¨ë¸: {self.model_name}, ì¶œë ¥: ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸, Google Search: í™œì„±í™”, ë‹¤ì¤‘ ì´ë¯¸ì§€: ì§€ì›")

    def _generate_image_hash(self, image_data: bytes) -> str:
        """ì´ë¯¸ì§€ ë°ì´í„°ì˜ í•´ì‹œê°’ ìƒì„±"""
        return hashlib.md5(image_data).hexdigest()

    def _generate_multiple_cache_key(self, image_data_list: List[bytes]) -> str:
        """ë‹¤ì¤‘ ì´ë¯¸ì§€ìš© ìºì‹œ í‚¤ ìƒì„±"""
        # ëª¨ë“  ì´ë¯¸ì§€ì˜ í•´ì‹œë¥¼ ì¡°í•©í•˜ì—¬ ìºì‹œ í‚¤ ìƒì„±
        combined_hash = hashlib.md5()
        for image_data in image_data_list:
            image_hash = hashlib.md5(image_data).hexdigest()
            combined_hash.update(image_hash.encode())
        
        return f"multiple_{len(image_data_list)}_{combined_hash.hexdigest()}"

    def _generate_step2_cache_key(self, grounded_facts: str) -> str:
        """Step 2ìš© ìºì‹œ í‚¤ ìƒì„± (grounded_facts í•´ì‹œ ê¸°ë°˜)"""
        # grounded_factsì˜ í•´ì‹œ ìƒì„±
        facts_hash = hashlib.md5(grounded_facts.encode('utf-8')).hexdigest()
        return f"step2_json_{facts_hash}"

    def _get_portfolio_analysis_prompt(self) -> str:
        """í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ìš© ë§ˆí¬ë‹¤ìš´ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return """
ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ì¦ê¶Œì‚¬ ì•± ìŠ¤í¬ë¦°ìƒ·ì—ì„œ ë³´ìœ  ì¢…ëª©ì„ ì¶”ì¶œí•˜ê³  ì¢…í•©ì ì¸ íˆ¬ì ë¶„ì„ì„ ìˆ˜í–‰í•˜ì„¸ìš”.

**ì¤‘ìš”: ë‹¤ìŒ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì •í™•íˆ ì¶œë ¥í•˜ì„¸ìš” (JSON ì—†ì´ ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ë§Œ):**

**AI ì´í‰:** [í¬íŠ¸í´ë¦¬ì˜¤ ì „ëµê³¼ ì£¼ìš” ë¦¬ìŠ¤í¬ë¥¼ 2-3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½]

**í¬íŠ¸í´ë¦¬ì˜¤ ì¢…í•© ë¦¬ë‹ˆì•„ ìŠ¤ì½”ì–´: [0-100 ì‚¬ì´ ì •ìˆ˜] / 100**

**3ëŒ€ í•µì‹¬ ê¸°ì¤€ ìŠ¤ì½”ì–´:**

- **ì„±ì¥ ì ì¬ë ¥:** [0-100 ì‚¬ì´ ì •ìˆ˜] / 100
- **ì•ˆì •ì„± ë° ë°©ì–´ë ¥:** [0-100 ì‚¬ì´ ì •ìˆ˜] / 100  
- **ì „ëµì  ì¼ê´€ì„±:** [0-100 ì‚¬ì´ ì •ìˆ˜] / 100

**[1] í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ë‹ˆì•„ ìŠ¤ì½”ì–´ ì‹¬ì¸µ ë¶„ì„**

**1.1 ì„±ì¥ ì ì¬ë ¥ ë¶„ì„ ([ì ìˆ˜] / 100): [ì œëª©]**

[ì„±ì¥ ì ì¬ë ¥ì— ëŒ€í•œ 3-4ë¬¸ì¥ì˜ êµ¬ì²´ì  ë¶„ì„]

**1.2 ì•ˆì •ì„± ë° ë°©ì–´ë ¥ ë¶„ì„ ([ì ìˆ˜] / 100): [ì œëª©]**

[ì•ˆì •ì„± ë° ë°©ì–´ë ¥ì— ëŒ€í•œ 3-4ë¬¸ì¥ì˜ êµ¬ì²´ì  ë¶„ì„]

**1.3 ì „ëµì  ì¼ê´€ì„± ë¶„ì„ ([ì ìˆ˜] / 100): [ì œëª©]**

[ì „ëµì  ì¼ê´€ì„±ì— ëŒ€í•œ 3-4ë¬¸ì¥ì˜ êµ¬ì²´ì  ë¶„ì„]

**[2] í¬íŠ¸í´ë¦¬ì˜¤ ê°•ì  ë° ì•½ì , ê·¸ë¦¬ê³  ê¸°íšŒ**

**ğŸ’ª ê°•ì **

- **[ê°•ì  1 ì œëª©]:** [1-2ë¬¸ì¥, ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸]
- **[ê°•ì  2 ì œëª©]:** [1-2ë¬¸ì¥, ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸]

**ğŸ“‰ ì•½ì **

- **[ì•½ì  1 ì œëª©]:** [1-2ë¬¸ì¥, êµ¬ì²´ì  ê°œì„ ë°©ì•ˆ]
- **[ì•½ì  2 ì œëª©]:** [1-2ë¬¸ì¥, êµ¬ì²´ì  ê°œì„ ë°©ì•ˆ]

**ğŸ’¡ ê¸°íšŒ ë° ê°œì„  ë°©ì•ˆ**

- **[ê¸°íšŒ 1 ì œëª©]:** [What-if ì‹œë‚˜ë¦¬ì˜¤ í¬í•¨í•œ ì„¤ëª…]
- **[ê¸°íšŒ 2 ì œëª©]:** [What-if ì‹œë‚˜ë¦¬ì˜¤ í¬í•¨í•œ ì„¤ëª…]

**[3] ê°œë³„ ì¢…ëª© ë¦¬ë‹ˆì•„ ìŠ¤ì½”ì–´ ìƒì„¸ ë¶„ì„**

**3.1 ìŠ¤ì½”ì–´ ìš”ì•½ í…Œì´ë¸”**

| ì£¼ì‹ | Overall (100ì  ë§Œì ) | í€ë”ë©˜íƒˆ | ê¸°ìˆ  ì ì¬ë ¥ | ê±°ì‹œê²½ì œ | ì‹œì¥ì‹¬ë¦¬ | CEO/ë¦¬ë”ì‹­ |
| --- | --- | --- | --- | --- | --- | --- |
| **[ì¢…ëª©ëª… 1]** | **[ì ìˆ˜]** | [ì ìˆ˜] | [ì ìˆ˜] | [ì ìˆ˜] | [ì ìˆ˜] | [ì ìˆ˜] |
| **[ì¢…ëª©ëª… 2]** | **[ì ìˆ˜]** | [ì ìˆ˜] | [ì ìˆ˜] | [ì ìˆ˜] | [ì ìˆ˜] | [ì ìˆ˜] |

**3.2 ê°œë³„ ì¢…ëª© ë¶„ì„ ì¹´ë“œ**

**1. [ì¢…ëª©ëª…] - Overall: [ì ìˆ˜] / 100**

- **í€ë”ë©˜íƒˆ ([ì ìˆ˜]/100):** [ì¬ë¬´ ìƒíƒœ ë° ì‹¤ì  ë¶„ì„]
- **ê¸°ìˆ  ì ì¬ë ¥ ([ì ìˆ˜]/100):** [ê¸°ìˆ ë ¥ ë° í˜ì‹  ëŠ¥ë ¥ ë¶„ì„]
- **ê±°ì‹œê²½ì œ ([ì ìˆ˜]/100):** [ê±°ì‹œê²½ì œì  ì˜í–¥ ë¶„ì„]
- **ì‹œì¥ì‹¬ë¦¬ ([ì ìˆ˜]/100):** [ì‹œì¥ ì¸ì‹ ë° íˆ¬ì ì‹¬ë¦¬ ë¶„ì„]
- **CEO/ë¦¬ë”ì‹­ ([ì ìˆ˜]/100):** [ê²½ì˜ì§„ ë¦¬ë”ì‹­ ë° ì „ëµ ë¶„ì„]

ë¶„ì„ ê·œì¹™:
1. AI ì´í‰: í¬íŠ¸í´ë¦¬ì˜¤ì˜ íˆ¬ì ì „ëµê³¼ ì£¼ìš” ë¦¬ìŠ¤í¬ë¥¼ 2-3ë¬¸ì¥ìœ¼ë¡œ ëª…í™•íˆ ìš”ì•½
2. ëª¨ë“  ì ìˆ˜ëŠ” 0-100 ì‚¬ì´ì˜ ì •ìˆ˜ë¡œ í‰ê°€
3. ê° ê¸°ì¤€ë³„ë¡œ 3-4ë¬¸ì¥ì˜ êµ¬ì²´ì ì´ê³  ì „ë¬¸ì ì¸ ë¶„ì„ ì œê³µ
4. ê°•ì /ì•½ì /ê¸°íšŒ: ê° í•­ëª©ì€ 1-2ë¬¸ì¥ìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ ì œê³µ
5. ê¸°íšŒì—ëŠ” ê°„ë‹¨í•œ "What-if" ì‹œë‚˜ë¦¬ì˜¤ í¬í•¨
6. ì‹ë³„ëœ ëª¨ë“  ì¢…ëª©ì— ëŒ€í•´ 5ê°€ì§€ ê¸°ì¤€ë³„ ìƒì„¸ í‰ê°€
7. ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” í•œêµ­ì–´ë¡œ ì‘ì„±
8. ì „ë¬¸ì ì¸ íˆ¬ì ë¶„ì„ ì–¸ì–´ ì‚¬ìš©
9. êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ ë°ì´í„° í¬ì¸íŠ¸ í¬í•¨

**ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ë§Œ ì¶œë ¥í•˜ê³ , JSONì´ë‚˜ ë‹¤ë¥¸ í˜•ì‹ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.**
"""

    def _get_multiple_image_prompt(self) -> str:
        """ë‹¤ì¤‘ ì´ë¯¸ì§€ ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸"""
        return """
        ë‹¹ì‹ ì€ í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ìœ„ì— ì œê³µëœ ì—¬ëŸ¬ í¬íŠ¸í´ë¦¬ì˜¤ ì´ë¯¸ì§€ë“¤ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.

        ê° ì´ë¯¸ì§€ë¥¼ ê°œë³„ì ìœ¼ë¡œ ë¶„ì„í•œ í›„, ì „ì²´ì ì¸ í¬íŠ¸í´ë¦¬ì˜¤ ìƒí™©ì„ ì¢…í•©í•˜ì—¬ 
        ë‹¤ìŒ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì •í™•íˆ ì¶œë ¥í•˜ì„¸ìš” (ì¶”ê°€ í…ìŠ¤íŠ¸ ì—†ì´):

        **AI ì´í‰:** [í¬íŠ¸í´ë¦¬ì˜¤ ì „ëµê³¼ ì£¼ìš” ë¦¬ìŠ¤í¬ë¥¼ 2-3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½]

        **í¬íŠ¸í´ë¦¬ì˜¤ ì¢…í•© ë¦¬ë‹ˆì•„ ìŠ¤ì½”ì–´: [0-100] / 100**

        **3ëŒ€ í•µì‹¬ ê¸°ì¤€ ìŠ¤ì½”ì–´:**

        - **ì„±ì¥ ì ì¬ë ¥:** [0-100] / 100
        - **ì•ˆì •ì„± ë° ë°©ì–´ë ¥:** [0-100] / 100
        - **ì „ëµì  ì¼ê´€ì„±:** [0-100] / 100

        **[1] í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ë‹ˆì•„ ìŠ¤ì½”ì–´ ì‹¬ì¸µ ë¶„ì„**

        **1.1 ì„±ì¥ ì ì¬ë ¥ ë¶„ì„ ([ì ìˆ˜] / 100): [ì œëª©]**

        [3-4ë¬¸ì¥ì˜ êµ¬ì²´ì  ë¶„ì„]

        **1.2 ì•ˆì •ì„± ë° ë°©ì–´ë ¥ ë¶„ì„ ([ì ìˆ˜] / 100): [ì œëª©]**

        [3-4ë¬¸ì¥ì˜ êµ¬ì²´ì  ë¶„ì„]

        **1.3 ì „ëµì  ì¼ê´€ì„± ë¶„ì„ ([ì ìˆ˜] / 100): [ì œëª©]**

        [3-4ë¬¸ì¥ì˜ êµ¬ì²´ì  ë¶„ì„]

        **[2] í¬íŠ¸í´ë¦¬ì˜¤ ê°•ì  ë° ì•½ì , ê·¸ë¦¬ê³  ê¸°íšŒ**

        **ğŸ’ª ê°•ì **

        - [ê°•ì  1: 1-2ë¬¸ì¥, ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸]
        - [ê°•ì  2: 1-2ë¬¸ì¥, ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸]

        **ğŸ“‰ ì•½ì **

        - [ì•½ì  1: 1-2ë¬¸ì¥, êµ¬ì²´ì  ê°œì„ ë°©ì•ˆ]
        - [ì•½ì  2: 1-2ë¬¸ì¥, êµ¬ì²´ì  ê°œì„ ë°©ì•ˆ]

        **ğŸ’¡ ê¸°íšŒ ë° ê°œì„  ë°©ì•ˆ**

        - [ê¸°íšŒ 1: What-if ì‹œë‚˜ë¦¬ì˜¤ í¬í•¨]
        - [ê¸°íšŒ 2: êµ¬ì²´ì  ì‹¤í–‰ ë°©ì•ˆ]

        **[3] ê°œë³„ ì¢…ëª© ë¦¬ë‹ˆì•„ ìŠ¤ì½”ì–´ ìƒì„¸ ë¶„ì„**

        **3.1 ìŠ¤ì½”ì–´ ìš”ì•½ í…Œì´ë¸”**

        | ì£¼ì‹ | Overall (100ì  ë§Œì ) | í€ë”ë©˜íƒˆ | ê¸°ìˆ  ì ì¬ë ¥ | ê±°ì‹œê²½ì œ | ì‹œì¥ì‹¬ë¦¬ | CEO/ë¦¬ë”ì‹­ |
        | --- | --- | --- | --- | --- | --- | --- |
        | [ì¢…ëª©ëª…] | [ì ìˆ˜] | [ì ìˆ˜] | [ì ìˆ˜] | [ì ìˆ˜] | [ì ìˆ˜] | [ì ìˆ˜] |

        **3.2 ê°œë³„ ì¢…ëª© ë¶„ì„ ì¹´ë“œ**

        **[ë²ˆí˜¸]. [ì¢…ëª©ëª…] - Overall: [ì ìˆ˜] / 100**

        - **í€ë”ë©˜íƒˆ ([ì ìˆ˜]/100):** [ìƒì„¸ ë¶„ì„]
        - **ê¸°ìˆ  ì ì¬ë ¥ ([ì ìˆ˜]/100):** [ìƒì„¸ ë¶„ì„]
        - **ê±°ì‹œê²½ì œ ([ì ìˆ˜]/100):** [ìƒì„¸ ë¶„ì„]
        - **ì‹œì¥ì‹¬ë¦¬ ([ì ìˆ˜]/100):** [ìƒì„¸ ë¶„ì„]
        - **CEO/ë¦¬ë”ì‹­ ([ì ìˆ˜]/100):** [ìƒì„¸ ë¶„ì„]

        ë‹¤ì¤‘ ì´ë¯¸ì§€ ë¶„ì„ ì‹œ ê³ ë ¤ì‚¬í•­:
        1. ê° ì´ë¯¸ì§€ì˜ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±ì„ ê°œë³„ì ìœ¼ë¡œ ë¶„ì„
        2. ì‹œê°„ì— ë”°ë¥¸ ë³€í™”ê°€ ìˆë‹¤ë©´ ì‹œê³„ì—´ ë¶„ì„ í¬í•¨
        3. ì „ì²´ì ì¸ íˆ¬ì ì „ëµì˜ ì¼ê´€ì„± í‰ê°€
        4. ë¦¬ìŠ¤í¬ ë¶„ì‚° ì •ë„ ì¢…í•© í‰ê°€
        5. ìˆ˜ìµë¥  ì¶”ì´ ë¶„ì„ (ì—¬ëŸ¬ ì‹œì ì´ ìˆëŠ” ê²½ìš°)

        ë¶„ì„ ê·œì¹™:
        - ëª¨ë“  ì ìˆ˜ëŠ” 0-100 ì‚¬ì´ì˜ ì •ìˆ˜ë¡œ í‰ê°€
        - ê° ë¶„ì„ì€ êµ¬ì²´ì ì´ê³  ì „ë¬¸ì ì¸ ë‚´ìš©ìœ¼ë¡œ ì‘ì„±
        - ê°•ì /ì•½ì /ê¸°íšŒëŠ” ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ ì œê³µ
        - ê¸°íšŒì—ëŠ” ê°„ë‹¨í•œ "What-if" ì‹œë‚˜ë¦¬ì˜¤ í¬í•¨
        - ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” í•œêµ­ì–´ë¡œ ì‘ì„±
        - ì „ë¬¸ì ì¸ íˆ¬ì ë¶„ì„ ì–¸ì–´ ì‚¬ìš©
        - êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ ë°ì´í„° í¬ì¸íŠ¸ í¬í•¨
        """

    async def _encode_image_to_base64(self, image_data: bytes) -> str:
        """ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ì¸ì½”ë”©"""
        try:
            # ì´ë¯¸ì§€ ìµœì í™”
            optimized_data = await optimize_image(image_data)
            return base64.b64encode(optimized_data).decode('utf-8')
        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ Base64 ì¸ì½”ë”© ì‹¤íŒ¨: {str(e)}")
            raise ValueError(f"ì´ë¯¸ì§€ ì¸ì½”ë”© ì‹¤íŒ¨: {str(e)}")

    async def _call_gemini_api(self, prompt: str, image_base64: str) -> str:
        """Gemini API í˜¸ì¶œ - ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ ë°˜í™˜"""
        for attempt in range(self.max_retries):
            try:
                logger.info(f"Gemini API í˜¸ì¶œ ì‹œë„ {attempt + 1}/{self.max_retries} (Google Search í™œì„±í™”)")
                
                # ì´ë¯¸ì§€ íŒŒíŠ¸ ìƒì„±
                image_part = Part.from_bytes(
                    data=base64.b64decode(image_base64),
                    mime_type="image/jpeg"
                )
                
                # ì„¤ì • ìƒì„± - ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ ìƒì„±ì— ìµœì í™”
                config = GenerateContentConfig(
                    temperature=0.3,  # ì¼ê´€ëœ ë¶„ì„ì„ ìœ„í•´ ë‚®ì€ ì˜¨ë„
                    top_p=0.9,
                    top_k=40,
                    max_output_tokens=32768,  # 16384 â†’ 32768ë¡œ ì¦ê°€ (ìµœëŒ€ ì œí•œ)
                    response_mime_type="text/plain"  # í”Œë ˆì¸ í…ìŠ¤íŠ¸ (ë§ˆí¬ë‹¤ìš´)
                )
                
                # Google Search ë„êµ¬ í™œì„±í™” (ì˜¬ë°”ë¥¸ ë°©ì‹)
                from google.genai import types
                grounding_tool = types.Tool(
                    google_search=types.GoogleSearch()
                )
                
                # configì— tools ì¶”ê°€
                config.tools = [grounding_tool]
                
                # API í˜¸ì¶œ (ë™ê¸° í˜¸ì¶œ)
                response = self.client.models.generate_content(
                    model=self.model_name,
                    contents=[prompt, image_part],
                    config=config
                )
                
                if response and response.text:
                    markdown_text = response.text.strip()
                    logger.info("Gemini API ë§ˆí¬ë‹¤ìš´ ì‘ë‹µ ì„±ê³µ (Google Search í†µí•©)")
                    return markdown_text
                else:
                    raise ValueError("Gemini APIì—ì„œ ë¹ˆ ì‘ë‹µ ë°›ìŒ")
                    
            except asyncio.TimeoutError:
                logger.warning(f"Gemini API íƒ€ì„ì•„ì›ƒ (ì‹œë„ {attempt + 1})")
                if attempt == self.max_retries - 1:
                    raise TimeoutError(f"API í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ: {self.timeout}ì´ˆ ì´ˆê³¼")
                await asyncio.sleep(2 ** attempt)  # ì§€ìˆ˜ì  ë°±ì˜¤í”„
                
            except Exception as e:
                logger.error(f"Gemini API í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}): {str(e)}")
                
                # Google Search ê´€ë ¨ ì˜¤ë¥˜ì¸ ê²½ìš° íŠ¹ë³„ ì²˜ë¦¬
                if "search" in str(e).lower():
                    logger.warning("Google Search ê¸°ëŠ¥ ê´€ë ¨ ì˜¤ë¥˜, ê¸°ë³¸ ë¶„ì„ìœ¼ë¡œ ê³„ì† ì§„í–‰")
                
                if attempt == self.max_retries - 1:
                    raise
                await asyncio.sleep(2 ** attempt)

    async def _call_gemini_api_multiple(self, image_data_list: List[bytes]) -> str:
        """
        Gemini API ë‹¤ì¤‘ ì´ë¯¸ì§€ í˜¸ì¶œ
        
        ì°¸ê³ : https://ai.google.dev/gemini-api/docs/image-understanding?hl=ko
        - ìš”ì²­ë‹¹ ìµœëŒ€ 3,600ê°œ ì´ë¯¸ì§€ ì§€ì› (ìš°ë¦¬ëŠ” 5ê°œë¡œ ì œí•œ)
        - ê° ì´ë¯¸ì§€ëŠ” 768x768 íƒ€ì¼ë¡œ ì²˜ë¦¬ë˜ë©° íƒ€ì¼ë‹¹ 258 í† í°
        """
        for attempt in range(self.max_retries):
            try:
                logger.info(f"Gemini API ë‹¤ì¤‘ ì´ë¯¸ì§€ í˜¸ì¶œ ì‹œë„ {attempt + 1}/{self.max_retries} (Google Search í™œì„±í™”)")
                
                # contents ë°°ì—´ êµ¬ì„± - ì´ë¯¸ì§€ë“¤ ë¨¼ì €, í”„ë¡¬í”„íŠ¸ëŠ” ë§ˆì§€ë§‰
                contents = []
                
                # 1. ì´ë¯¸ì§€ë“¤ì„ contentsì— ì¶”ê°€
                for i, image_data in enumerate(image_data_list):
                    try:
                        image_part = Part.from_bytes(
                            data=image_data,
                            mime_type='image/jpeg'
                        )
                        contents.append(image_part)
                        logger.debug(f"ì´ë¯¸ì§€ {i+1} ì¶”ê°€ë¨ (í¬ê¸°: {len(image_data)} bytes)")
                    except Exception as e:
                        logger.error(f"ì´ë¯¸ì§€ {i+1} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
                        raise ValueError(f"ì´ë¯¸ì§€ {i+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                
                # 2. ë‹¤ì¤‘ ì´ë¯¸ì§€ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
                prompt = self._get_multiple_image_prompt()
                contents.append(prompt)
                
                # 3. Google Search ë„êµ¬ ì„¤ì •
                from google.genai import types
                grounding_tool = types.Tool(
                    google_search=types.GoogleSearch()
                )
                
                # 4. ëª¨ë¸ ì„¤ì •
                config = GenerateContentConfig(
                    temperature=0.1,
                    max_output_tokens=32768,  # 16384 â†’ 32768ë¡œ ì¦ê°€ (ìµœëŒ€ ì œí•œ)
                    tools=[grounding_tool]
                )
                
                # 5. API í˜¸ì¶œ (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
                try:
                    response = self.client.models.generate_content(
                        model=self.model_name,
                        contents=contents,
                        config=config
                    )
                except asyncio.TimeoutError:
                    logger.error(f"Gemini API ë‹¤ì¤‘ ì´ë¯¸ì§€ í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ (ì‹œë„ {attempt + 1})")
                    if attempt == self.max_retries - 1:
                        raise TimeoutError(f"API í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ: {self.timeout}ì´ˆ ì´ˆê³¼")
                    await asyncio.sleep(2 ** attempt)
                    continue
                
                if response and response.text:
                    logger.info("Gemini API ë‹¤ì¤‘ ì´ë¯¸ì§€ ë§ˆí¬ë‹¤ìš´ ì‘ë‹µ ì„±ê³µ (Google Search í†µí•©)")
                    return response.text
                else:
                    raise ValueError("Gemini APIê°€ ë¹ˆ ì‘ë‹µì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.")
                    
            except TimeoutError:
                # TimeoutErrorëŠ” ì´ë¯¸ ì²˜ë¦¬ë¨
                raise
            except ValueError as e:
                # ValueErrorëŠ” ì¬ì‹œë„í•˜ì§€ ì•Šê³  ì¦‰ì‹œ ì „íŒŒ
                logger.error(f"Gemini API ë‹¤ì¤‘ ì´ë¯¸ì§€ í˜¸ì¶œ ê°’ ì˜¤ë¥˜: {str(e)}")
                raise
            except Exception as e:
                logger.error(f"Gemini API ë‹¤ì¤‘ ì´ë¯¸ì§€ í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}): {str(e)}")
                
                # íŠ¹ì • ì—ëŸ¬ íƒ€ì…ë³„ ì²˜ë¦¬
                error_str = str(e).lower()
                if "search" in error_str:
                    logger.warning("Google Search ê¸°ëŠ¥ ê´€ë ¨ ì˜¤ë¥˜, ê¸°ë³¸ ë¶„ì„ìœ¼ë¡œ ê³„ì† ì§„í–‰")
                elif "quota" in error_str or "limit" in error_str:
                    logger.error("API í• ë‹¹ëŸ‰ ì´ˆê³¼ ë˜ëŠ” ì œí•œ ë„ë‹¬")
                    raise ValueError("API ì‚¬ìš©ëŸ‰ì´ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
                elif "invalid" in error_str or "malformed" in error_str:
                    logger.error("ì˜ëª»ëœ ìš”ì²­ í˜•ì‹")
                    raise ValueError("ìš”ì²­ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                
                if attempt == self.max_retries - 1:
                    raise
                await asyncio.sleep(2 ** attempt)

    def _validate_markdown_response(self, markdown_text: str) -> str:
        """ë§ˆí¬ë‹¤ìš´ ì‘ë‹µ ê²€ì¦ ë° ì •ì œ"""
        try:
            # ê¸°ë³¸ ê²€ì¦
            if not markdown_text or len(markdown_text.strip()) < 100:
                raise ValueError("ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤.")
            
            # í•„ìˆ˜ ì„¹ì…˜ í™•ì¸
            required_sections = [
                "**AI ì´í‰:**",
                "**í¬íŠ¸í´ë¦¬ì˜¤ ì¢…í•© ë¦¬ë‹ˆì•„ ìŠ¤ì½”ì–´:",
                "**3ëŒ€ í•µì‹¬ ê¸°ì¤€ ìŠ¤ì½”ì–´:**",
                "**ì„±ì¥ ì ì¬ë ¥:**",
                "**ì•ˆì •ì„± ë° ë°©ì–´ë ¥:**",
                "**ì „ëµì  ì¼ê´€ì„±:**"
            ]
            
            for section in required_sections:
                if section not in markdown_text:
                    logger.warning(f"í•„ìˆ˜ ì„¹ì…˜ ëˆ„ë½: {section}")
            
            logger.info("ë§ˆí¬ë‹¤ìš´ ì‘ë‹µ ê²€ì¦ ì™„ë£Œ")
            return markdown_text.strip()
            
        except Exception as e:
            logger.error(f"ë§ˆí¬ë‹¤ìš´ ì‘ë‹µ ê²€ì¦ ì‹¤íŒ¨: {str(e)}")
            raise ValueError(f"ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {str(e)}")

    async def analyze_portfolio_image(
        self, 
        image_data: bytes, 
        use_cache: bool = True
    ) -> str:
        """
        í¬íŠ¸í´ë¦¬ì˜¤ ì´ë¯¸ì§€ ë¶„ì„ - ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ ë°˜í™˜
        
        Args:
            image_data: ì´ë¯¸ì§€ ë°”ì´íŠ¸ ë°ì´í„°
            use_cache: ìºì‹œ ì‚¬ìš© ì—¬ë¶€
            
        Returns:
            str: expected_result.mdì™€ ë™ì¼í•œ í˜•ì‹ì˜ ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸
            
        Raises:
            ValueError: ì´ë¯¸ì§€ ê²€ì¦ ì‹¤íŒ¨ ë˜ëŠ” API ì‘ë‹µ ê²€ì¦ ì‹¤íŒ¨
            TimeoutError: API í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ
            Exception: ê¸°íƒ€ ì˜ˆì™¸
        """
        try:
            # ì´ë¯¸ì§€ ê²€ì¦
            await validate_image(image_data)
            
            # ìºì‹œ í™•ì¸
            if use_cache:
                image_hash = self._generate_image_hash(image_data)
                if image_hash in self._cache:
                    logger.info("ìºì‹œëœ ë¶„ì„ ê²°ê³¼ ë°˜í™˜")
                    return self._cache[image_hash]
            
            # ì´ë¯¸ì§€ Base64 ì¸ì½”ë”©
            image_base64 = await self._encode_image_to_base64(image_data)
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._get_portfolio_analysis_prompt()
            
            # Gemini API í˜¸ì¶œ
            markdown_text = await self._call_gemini_api(prompt, image_base64)
            
            # ë§ˆí¬ë‹¤ìš´ ì‘ë‹µ ê²€ì¦
            validated_markdown = self._validate_markdown_response(markdown_text)
            
            # ìºì‹œ ì €ì¥
            if use_cache:
                self._cache[image_hash] = validated_markdown
                logger.info(f"ë¶„ì„ ê²°ê³¼ ìºì‹œ ì €ì¥ (í•´ì‹œ: {image_hash[:8]})")
            
            return validated_markdown
            
        except Exception as e:
            logger.error(f"í¬íŠ¸í´ë¦¬ì˜¤ ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            raise

    async def analyze_multiple_portfolio_images(self, image_data_list: List[bytes]) -> str:
        """
        ë‹¤ì¤‘ í¬íŠ¸í´ë¦¬ì˜¤ ì´ë¯¸ì§€ ë¶„ì„
        
        Args:
        	image_data_list: ì´ë¯¸ì§€ ë°”ì´íŠ¸ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        
        Returns:
            str: ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ë¶„ì„ ê²°ê³¼
            
        Raises:
            ValueError: ì´ë¯¸ì§€ ê²€ì¦ ì‹¤íŒ¨ ë˜ëŠ” API ì‘ë‹µ ê²€ì¦ ì‹¤íŒ¨
            TimeoutError: API í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ
            Exception: ê¸°íƒ€ ì˜ˆì™¸
        """
        try:
            # ì…ë ¥ ê²€ì¦
            if not image_data_list or len(image_data_list) == 0:
                raise ValueError("ë¶„ì„í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            if len(image_data_list) > 5:
                raise ValueError("ìµœëŒ€ 5ê°œì˜ ì´ë¯¸ì§€ë§Œ ë¶„ì„ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
            
            # ê° ì´ë¯¸ì§€ ê²€ì¦
            for i, image_data in enumerate(image_data_list):
                try:
                    await validate_image(image_data)
                except ValueError as e:
                    logger.error(f"ì´ë¯¸ì§€ {i+1} ê²€ì¦ ì‹¤íŒ¨: {str(e)}")
                    raise ValueError(f"ì´ë¯¸ì§€ {i+1} ê²€ì¦ ì‹¤íŒ¨: {str(e)}")
            
            # ìºì‹œ í‚¤ ìƒì„± (ëª¨ë“  ì´ë¯¸ì§€ì˜ í•´ì‹œ ì¡°í•©)
            cache_key = self._generate_multiple_cache_key(image_data_list)
            if cache_key in self._cache:
                logger.info("ë‹¤ì¤‘ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ìºì‹œì—ì„œ ë°˜í™˜")
                return self._cache[cache_key]
            
            # ë‹¤ì¤‘ ì´ë¯¸ì§€ API í˜¸ì¶œ
            try:
                result = await self._call_gemini_api_multiple(image_data_list)
            except TimeoutError as e:
                logger.error(f"ë‹¤ì¤‘ ì´ë¯¸ì§€ ë¶„ì„ íƒ€ì„ì•„ì›ƒ: {str(e)}")
                raise TimeoutError(f"ë¶„ì„ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë³µì¡í•œ í¬íŠ¸í´ë¦¬ì˜¤ì˜ ê²½ìš° ìµœëŒ€ 10ë¶„ê¹Œì§€ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
            except ValueError as e:
                logger.error(f"ë‹¤ì¤‘ ì´ë¯¸ì§€ ë¶„ì„ ê°’ ì˜¤ë¥˜: {str(e)}")
                raise
            except Exception as e:
                logger.error(f"ë‹¤ì¤‘ ì´ë¯¸ì§€ API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
                raise ValueError(f"AI ë¶„ì„ ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
            
            # ê²°ê³¼ ê²€ì¦ ë° ìºì‹±
            try:
                validated_result = self._validate_markdown_response(result)
            except ValueError as e:
                logger.error(f"ë‹¤ì¤‘ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ê²€ì¦ ì‹¤íŒ¨: {str(e)}")
                raise ValueError(f"ë¶„ì„ ê²°ê³¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
            
            self._cache[cache_key] = validated_result
            
            logger.info(f"ë‹¤ì¤‘ ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ ({len(image_data_list)}ê°œ ì´ë¯¸ì§€)")
            return validated_result
            
        except (ValueError, TimeoutError):
            # ì´ë¯¸ ì²˜ë¦¬ëœ ì˜ˆì™¸ëŠ” ê·¸ëŒ€ë¡œ ì „íŒŒ
            raise
        except Exception as e:
            logger.error(f"ë‹¤ì¤‘ ì´ë¯¸ì§€ ë¶„ì„ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}", exc_info=True)
            raise ValueError(f"ë¶„ì„ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")

    async def get_sample_analysis(self) -> str:
        """ìƒ˜í”Œ ë¶„ì„ ê²°ê³¼ ë°˜í™˜ (í…ŒìŠ¤íŠ¸ìš©) - ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸"""
        try:
            logger.info("ìƒ˜í”Œ ë§ˆí¬ë‹¤ìš´ ë¶„ì„ ê²°ê³¼ ë°˜í™˜")
            return SAMPLE_MARKDOWN_CONTENT
        except Exception as e:
            logger.error(f"ìƒ˜í”Œ ë¶„ì„ ê²°ê³¼ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise ValueError(f"ìƒ˜í”Œ ë°ì´í„° ì˜¤ë¥˜: {str(e)}")

    # ============================================
    # êµ¬ì¡°í™”ëœ ì¶œë ¥ ë©”ì„œë“œ (Phase 6 ì¶”ê°€)
    # ============================================

    def _get_grounding_prompt(self) -> str:
        """Step 1: ê²€ìƒ‰Â·ê·¸ë¼ìš´ë”©ìš© í”„ë¡¬í”„íŠ¸ (êµ¬ì¡°í™”ëœ ë§ˆí¬ë‹¤ìš´ ì¶œë ¥)"""
        return """
ë‹¹ì‹ ì€ ì „ë¬¸ í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì œê³µëœ í¬íŠ¸í´ë¦¬ì˜¤ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ 
ë‹¤ìŒ êµ¬ì¡°í™”ëœ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”.

**ì¤‘ìš”**: Google Searchë¥¼ í™œìš©í•˜ì—¬ ìµœì‹  ì‹œì¥ ì •ë³´, ì¬ë¬´ ë°ì´í„°, ë‰´ìŠ¤ë¥¼ ë°˜ì˜í•˜ì„¸ìš”.

ì¶œë ¥ í˜•ì‹:

---

### **í¬íŠ¸í´ë¦¬ì˜¤ ì¢…í•© ìŠ¤ì½”ì–´**

* **í¬íŠ¸í´ë¦¬ì˜¤ ì¢…í•© ë¦¬ë‹ˆì•„ ìŠ¤ì½”ì–´: [0-100 ì •ìˆ˜] / 100**

### **í¬íŠ¸í´ë¦¬ì˜¤ ì‹¬ì¸µ ë¶„ì„**

**1. 3ëŒ€ í•µì‹¬ ê¸°ì¤€ ìŠ¤ì½”ì–´**
* ì„±ì¥ ì ì¬ë ¥: [0-100 ì •ìˆ˜] / 100
* ì•ˆì •ì„± ë° ë°©ì–´ë ¥: [0-100 ì •ìˆ˜] / 100
* ì „ëµì  ì¼ê´€ì„±: [0-100 ì •ìˆ˜] / 100

**2. ê°œë³„ ì¢…ëª© ë¦¬ë‹ˆì•„ ìŠ¤ì½”ì–´**
| ì£¼ì‹ | Overall (100ì  ë§Œì ) | í€ë”ë©˜íƒˆ | ê¸°ìˆ  ì ì¬ë ¥ | ê±°ì‹œê²½ì œ | ì‹œì¥ì‹¬ë¦¬ | CEO/ë¦¬ë”ì‹­ |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **[ì¢…ëª©ëª…]** | [ì ìˆ˜] | [ì ìˆ˜] | [ì ìˆ˜] | [ì ìˆ˜] | [ì ìˆ˜] | [ì ìˆ˜] |

**3. ê°œë³„ ì¢…ëª© ë¶„ì„ ì„¤ëª… (ë¶„ì„ ì¹´ë“œ)**

**1. [ì¢…ëª©ëª…] - Overall: [ì ìˆ˜] / 100**
* **í€ë”ë©˜íƒˆ ([ì ìˆ˜]/100):** [ìµœì†Œ 30ì ë¶„ì„ - ìµœì‹  ì¬ë¬´ ë°ì´í„° í¬í•¨]
* **ê¸°ìˆ  ì ì¬ë ¥ ([ì ìˆ˜]/100):** [ìµœì†Œ 30ì ë¶„ì„ - ìµœì‹  ê¸°ìˆ  ë™í–¥ í¬í•¨]
* **ê±°ì‹œê²½ì œ ([ì ìˆ˜]/100):** [ìµœì†Œ 30ì ë¶„ì„ - ìµœì‹  ê²½ì œ ì „ë§ í¬í•¨]
* **ì‹œì¥ì‹¬ë¦¬ ([ì ìˆ˜]/100):** [ìµœì†Œ 30ì ë¶„ì„ - ìµœì‹  ì‹œì¥ ë™í–¥ í¬í•¨]
* **CEO/ë¦¬ë”ì‹­ ([ì ìˆ˜]/100):** [ìµœì†Œ 30ì ë¶„ì„]

### **ì‹¬ì¸µ ë¶„ì„ ì„¤ëª…**

* **1.1 ì„±ì¥ ì ì¬ë ¥ ë¶„ì„ ([ì ìˆ˜] / 100): [ì œëª©]**
    [ìµœì†Œ 50ì ìƒì„¸ ë¶„ì„ - Google Searchë¡œ ìµœì‹  ì„±ì¥ ì „ë§ ë°˜ì˜]

* **1.2 ì•ˆì •ì„± ë° ë°©ì–´ë ¥ ë¶„ì„ ([ì ìˆ˜] / 100): [ì œëª©]**
    [ìµœì†Œ 50ì ìƒì„¸ ë¶„ì„ - ìµœì‹  ë¦¬ìŠ¤í¬ ìš”ì¸ í¬í•¨]

* **1.3 ì „ëµì  ì¼ê´€ì„± ë¶„ì„ ([ì ìˆ˜] / 100): [ì œëª©]**
    [ìµœì†Œ 50ì ìƒì„¸ ë¶„ì„]

### **í¬íŠ¸í´ë¦¬ì˜¤ ê°•ì , ì•½ì  ë° ê¸°íšŒ (ì„¤ëª…)**

* **ğŸ’ª ê°•ì **
    * **[ê°•ì  1 ì œëª©]:** [1-2ë¬¸ì¥]
    * **[ê°•ì  2 ì œëª©]:** [1-2ë¬¸ì¥]

* **ğŸ“‰ ì•½ì **
    * **[ì•½ì  1 ì œëª©]:** [1-2ë¬¸ì¥]
    * **[ì•½ì  2 ì œëª©]:** [1-2ë¬¸ì¥]

* **ğŸ’¡ ê¸°íšŒ ë° ê°œì„  ë°©ì•ˆ**
    * **[ê¸°íšŒ 1 ì œëª©]:** [What-if ì‹œë‚˜ë¦¬ì˜¤ í¬í•¨, ìµœì†Œ 30ì]
    * **[ê¸°íšŒ 2 ì œëª©]:** [êµ¬ì²´ì  ì‹¤í–‰ ë°©ì•ˆ, ìµœì†Œ 30ì]

---

ë¶„ì„ ê·œì¹™:
1. ëª¨ë“  ì ìˆ˜ëŠ” 0-100 ì‚¬ì´ì˜ ì •ìˆ˜ë¡œë§Œ í‘œê¸°
2. Google Searchë¡œ ê° ì¢…ëª©ì˜ ìµœì‹  ë‰´ìŠ¤, ì¬ë¬´ ë°ì´í„°, ì‹œì¥ ë™í–¥ ë°˜ì˜
3. ë¶„ì„ì€ êµ¬ì²´ì ì´ê³  ì „ë¬¸ì ì¸ ë‚´ìš©ìœ¼ë¡œ ì‘ì„±
4. ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” í•œêµ­ì–´ë¡œ ì‘ì„±
5. ìœ„ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ì •í™•íˆ ë”°ë¥´ë˜, ì¶”ê°€ ì„¤ëª…ì´ë‚˜ ì½”ë©˜íŠ¸ëŠ” ë„£ì§€ ë§ˆì„¸ìš”
"""

    async def _generate_grounded_facts(self, image_data_list: List[bytes]) -> str:
        """
        Step 1: Google Search Toolë¡œ ìµœì‹  ì •ë³´ ìˆ˜ì§‘ ë° êµ¬ì¡°í™”ëœ ë§ˆí¬ë‹¤ìš´ ìƒì„±
        
        Args:
            image_data_list: ì´ë¯¸ì§€ ë°”ì´íŠ¸ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            
        Returns:
            str: êµ¬ì¡°í™”ëœ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ë¶„ì„ ê²°ê³¼ (ì ìˆ˜, í…Œì´ë¸”, ìƒì„¸ ë¶„ì„ í¬í•¨)
            
        Raises:
            ValueError: API í˜¸ì¶œ ì‹¤íŒ¨
        """
        # ìºì‹œ í‚¤ ìƒì„± (ì´ë¯¸ì§€ í•´ì‹œ ê¸°ë°˜)
        cache_key = f"grounded_{self._generate_multiple_cache_key(image_data_list)}"
        if cache_key in self._cache:
            logger.info("Step 1 ìºì‹œëœ ê²°ê³¼ ë°˜í™˜")
            return self._cache[cache_key]
        
        for attempt in range(self.max_retries):
            try:
                logger.info(
                    f"Step 1: ê²€ìƒ‰Â·ê·¸ë¼ìš´ë”© í˜¸ì¶œ ì‹œë„ {attempt + 1}/{self.max_retries}"
                )
                
                # Contents ë°°ì—´ êµ¬ì„±
                contents: List[Union[str, Part]] = []
                
                # 1) ì´ë¯¸ì§€ íŒŒíŠ¸ë“¤ ì¶”ê°€
                for i, image_data in enumerate(image_data_list):
                    image_part = Part.from_bytes(data=image_data, mime_type="image/jpeg")
                    contents.append(image_part)
                    logger.debug(f"Step 1: ì´ë¯¸ì§€ {i+1}/{len(image_data_list)} ì¶”ê°€")
                
                # 2) ê·¸ë¼ìš´ë”© í”„ë¡¬í”„íŠ¸ ì¶”ê°€
                contents.append(self._get_grounding_prompt())
                
                # 3) Google Search Tool ì„¤ì •
                from google.genai import types
                grounding_tool = types.Tool(google_search=types.GoogleSearch())
                
                # 4) ì„¤ì •: Google Search í™œì„±í™”, response_mime_type ë¯¸ì§€ì •
                config = GenerateContentConfig(
                    temperature=0.1,  # ì¼ê´€ëœ ì •ë³´ ìˆ˜ì§‘ì„ ìœ„í•´ ë‚®ì€ ì˜¨ë„
                    max_output_tokens=32768,  # 8192 â†’ 16384ë¡œ ì¦ê°€
                    tools=[grounding_tool],
                    # response_mime_type ë¯¸ì§€ì • - í…ìŠ¤íŠ¸ ì‘ë‹µ
                )
                
                # 5) API í˜¸ì¶œ
                response = self.client.models.generate_content(
                    model=self.model_name,
                    contents=contents,
                    config=config
                )
                
                # 6) ì‘ë‹µ ê²€ì¦ ë° ë°˜í™˜
                if response and getattr(response, "text", None):
                    result_text = response.text.strip()
                    
                    # ê¸°ë³¸ ê²€ì¦ (ìµœì†Œ ê¸¸ì´, í•„ìˆ˜ ì„¹ì…˜ í™•ì¸)
                    if len(result_text) < 500:
                        raise ValueError("Step 1 ì‘ë‹µì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤.")
                    
                    # í•„ìˆ˜ ì„¹ì…˜ í™•ì¸
                    required_sections = [
                        "í¬íŠ¸í´ë¦¬ì˜¤ ì¢…í•© ë¦¬ë‹ˆì•„ ìŠ¤ì½”ì–´:",
                        "3ëŒ€ í•µì‹¬ ê¸°ì¤€ ìŠ¤ì½”ì–´",
                        "ê°œë³„ ì¢…ëª© ë¦¬ë‹ˆì•„ ìŠ¤ì½”ì–´",
                        "ê°œë³„ ì¢…ëª© ë¶„ì„ ì„¤ëª…",
                        "ì‹¬ì¸µ ë¶„ì„ ì„¤ëª…",
                        "í¬íŠ¸í´ë¦¬ì˜¤ ê°•ì , ì•½ì  ë° ê¸°íšŒ"
                    ]
                    
                    for section in required_sections:
                        if section not in result_text:
                            logger.warning(f"Step 1: í•„ìˆ˜ ì„¹ì…˜ ëˆ„ë½ - {section}")
                    
                    # ìºì‹œ ì €ì¥
                    self._cache[cache_key] = result_text
                    
                    return result_text
                
                raise ValueError("Step 1: Gemini APIì—ì„œ ë¹ˆ ì‘ë‹µ ë°›ìŒ")
                
            except Exception as e:
                logger.error(f"Step 1 í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}): {str(e)}")
                if attempt == self.max_retries - 1:
                    raise ValueError(f"Step 1 ê²€ìƒ‰Â·ê·¸ë¼ìš´ë”© ì‹¤íŒ¨: {str(e)}")
                await asyncio.sleep(2 ** attempt)

    def _get_json_generation_prompt(self, grounded_facts: str) -> str:
        """Step 2: JSON ìŠ¤í‚¤ë§ˆ ìƒì„±ìš© í”„ë¡¬í”„íŠ¸ (í•„ë“œëª… ëª…ì‹œ)"""
        return f"""
ë‹¹ì‹ ì€ ë°ì´í„° ë³€í™˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì½ê³  ì •í™•íˆ JSONìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”.

## ì…ë ¥ ë°ì´í„° (Step 1ì—ì„œ ìˆ˜ì§‘ëœ ë¶„ì„ ê²°ê³¼):
```
{grounded_facts}
```

## ì¶œë ¥ JSON êµ¬ì¡° (ì •í™•íˆ ì´ í•„ë“œëª…ê³¼ íƒ€ì… ì‚¬ìš©):
{{
  "version": "1.0",
  "reportDate": "2025-10-01",
  "tabs": [
    {{
      "tabId": "dashboard",
      "tabTitle": "ì´ê´„ ìš”ì•½",
      "content": {{
        "overallScore": {{"title": "í¬íŠ¸í´ë¦¬ì˜¤ ì¢…í•© ë¦¬ë‹ˆì•„ ìŠ¤ì½”ì–´", "score": 72, "maxScore": 100}},
        "coreCriteriaScores": [
          {{"criterion": "ì„±ì¥ ì ì¬ë ¥", "score": 88, "maxScore": 100}},
          {{"criterion": "ì•ˆì •ì„± ë° ë°©ì–´ë ¥", "score": 55, "maxScore": 100}},
          {{"criterion": "ì „ëµì  ì¼ê´€ì„±", "score": 74, "maxScore": 100}}
        ],
        "strengths": ["ì„ êµ¬ì ì¸ ë¯¸ë˜ ê¸°ìˆ  íˆ¬ì", "ëª…í™•í•œ íˆ¬ì í…Œë§ˆ"],
        "weaknesses": ["ê·¹ì‹¬í•œ ë³€ë™ì„± ë…¸ì¶œ", "ì„¹í„° ì§‘ì¤‘ ë¦¬ìŠ¤í¬"]
      }}
    }},
    {{
      "tabId": "deepDive",
      "tabTitle": "í¬íŠ¸í´ë¦¬ì˜¤ ì‹¬ì¸µ ë¶„ì„",
      "content": {{
        "inDepthAnalysis": [
          {{"title": "ì„±ì¥ ì ì¬ë ¥ ë¶„ì„: ì œëª©", "score": 88, "description": "ìµœì†Œ 50ì ì´ìƒì˜ ìƒì„¸ ë¶„ì„ ë‚´ìš©"}},
          {{"title": "ì•ˆì •ì„± ë° ë°©ì–´ë ¥ ë¶„ì„: ì œëª©", "score": 55, "description": "ìµœì†Œ 50ì ì´ìƒì˜ ìƒì„¸ ë¶„ì„ ë‚´ìš©"}},
          {{"title": "ì „ëµì  ì¼ê´€ì„± ë¶„ì„: ì œëª©", "score": 74, "description": "ìµœì†Œ 50ì ì´ìƒì˜ ìƒì„¸ ë¶„ì„ ë‚´ìš©"}}
        ],
        "opportunities": {{
          "title": "ê¸°íšŒ ë° ê°œì„  ë°©ì•ˆ",
          "items": [
            {{"summary": "ì•ˆì •ì ì¸ í•µì‹¬ ìì‚° ì¶”ê°€", "details": "ìµœì†Œ 30ì ì´ìƒì˜ ìƒì„¸ ì„¤ëª…"}},
            {{"summary": "ìœ ì‚¬ í…Œë§ˆ ë‚´ ë¶„ì‚°", "details": "ìµœì†Œ 30ì ì´ìƒì˜ ìƒì„¸ ì„¤ëª…"}}
          ]
        }}
      }}
    }},
    {{
      "tabId": "allStockScores",
      "tabTitle": "ê°œë³„ ì¢…ëª© ìŠ¤ì½”ì–´",
      "content": {{
        "scoreTable": {{
          "headers": ["ì£¼ì‹", "Overall", "í€ë”ë©˜íƒˆ", "ê¸°ìˆ  ì ì¬ë ¥", "ê±°ì‹œê²½ì œ", "ì‹œì¥ì‹¬ë¦¬", "CEO/ë¦¬ë”ì‹­"],
          "rows": [
            {{"ì£¼ì‹": "íŒ”ë€í‹°ì–´ (PLTR)", "Overall": 78, "í€ë”ë©˜íƒˆ": 70, "ê¸°ìˆ  ì ì¬ë ¥": 95, "ê±°ì‹œê²½ì œ": 75, "ì‹œì¥ì‹¬ë¦¬": 85, "CEO/ë¦¬ë”ì‹­": 85}},
            {{"ì£¼ì‹": "ë¸Œë¡œë“œì»´ (AVGO)", "Overall": 82, "í€ë”ë©˜íƒˆ": 85, "ê¸°ìˆ  ì ì¬ë ¥": 80, "ê±°ì‹œê²½ì œ": 80, "ì‹œì¥ì‹¬ë¦¬": 80, "CEO/ë¦¬ë”ì‹­": 85}}
          ]
        }}
      }}
    }},
    {{
      "tabId": "keyStockAnalysis",
      "tabTitle": "í•µì‹¬ ì¢…ëª© ìƒì„¸ ë¶„ì„",
      "content": {{
        "analysisCards": [
          {{
            "stockName": "íŒ”ë€í‹°ì–´ (PLTR)",
            "overallScore": 78,
            "detailedScores": [
              {{"category": "í€ë”ë©˜íƒˆ", "score": 70, "analysis": "ìµœì†Œ 30ì ì´ìƒì˜ ë¶„ì„"}},
              {{"category": "ê¸°ìˆ  ì ì¬ë ¥", "score": 95, "analysis": "ìµœì†Œ 30ì ì´ìƒì˜ ë¶„ì„"}},
              {{"category": "ê±°ì‹œê²½ì œ", "score": 75, "analysis": "ìµœì†Œ 30ì ì´ìƒì˜ ë¶„ì„"}},
              {{"category": "ì‹œì¥ì‹¬ë¦¬", "score": 85, "analysis": "ìµœì†Œ 30ì ì´ìƒì˜ ë¶„ì„"}},
              {{"category": "CEO/ë¦¬ë”ì‹­", "score": 85, "analysis": "ìµœì†Œ 30ì ì´ìƒì˜ ë¶„ì„"}}
            ]
          }}
        ]
      }}
    }}
  ]
}}

## ì¤‘ìš”í•œ í•„ë“œëª… ê·œì¹™ (ì •í™•íˆ ì§€ì¼œì•¼ í•¨):
- coreCriteriaScores: [{{"criterion": "ì´ë¦„", "score": ìˆ«ì, "maxScore": 100}}]  â† criterion í•„ë“œ ì‚¬ìš©
- strengths: ["ë¬¸ìì—´1", "ë¬¸ìì—´2"]  â† ë¬¸ìì—´ ë°°ì—´
- weaknesses: ["ë¬¸ìì—´1", "ë¬¸ìì—´2"]  â† ë¬¸ìì—´ ë°°ì—´
- opportunities: {{"title": "...", "items": [...]}}  â† ê°ì²´ (ë°°ì—´ ì•„ë‹˜!)
- rows: [{{"ì£¼ì‹": "ì´ë¦„", "Overall": ìˆ«ì, "í€ë”ë©˜íƒˆ": ìˆ«ì, ...}}]  â† ê°ì²´ ë°°ì—´ (ë‹¨ìˆœ ë°°ì—´ ì•„ë‹˜!)
- detailedScores: [{{"category": "ì´ë¦„", "score": ìˆ«ì, "analysis": "í…ìŠ¤íŠ¸"}}]  â† ë°˜ë“œì‹œ í¬í•¨

## ë³€í™˜ ê·œì¹™:
1. **null ê°’ ì ˆëŒ€ ê¸ˆì§€**: ëª¨ë“  ì ìˆ˜ëŠ” 0-100 ì‚¬ì´ì˜ ì •ìˆ˜ë¡œ ì±„ì›Œì•¼ í•¨ (null, None ì‚¬ìš© ê¸ˆì§€)
2. **ìµœì†Œ ë¬¸ì ìˆ˜ í•„ìˆ˜**: 
   - description (ì‹¬ì¸µ ë¶„ì„): ìµœì†Œ 50ì ì´ìƒ
   - analysis (ê°œë³„ ì¢…ëª©): ìµœì†Œ 30ì ì´ìƒ
   - details (ê¸°íšŒ): ìµœì†Œ 30ì ì´ìƒ
   - ì§§ì„ ê²½ìš° "...ì— ëŒ€í•œ ë¶„ì„ì…ë‹ˆë‹¤" ë“±ìœ¼ë¡œ ëŠ˜ë¦´ ê²ƒ
3. **scoreTable.rows**: ëª¨ë“  ì ìˆ˜ í•„ë“œ(Overall, í€ë”ë©˜íƒˆ, ê¸°ìˆ  ì ì¬ë ¥, ê±°ì‹œê²½ì œ, ì‹œì¥ì‹¬ë¦¬, CEO/ë¦¬ë”ì‹­)ëŠ” ë°˜ë“œì‹œ ì •ìˆ˜ê°’
4. **detailedScores**: 5ê°œ ì¹´í…Œê³ ë¦¬ ëª¨ë‘ score(ì •ìˆ˜), analysis(30ì ì´ìƒ) í•„ìˆ˜
5. ëª¨ë“  ì ìˆ˜ëŠ” 0-100 ì‚¬ì´ì˜ ì •ìˆ˜ê°’ (ë²”ìœ„ í‘œê¸° ê¸ˆì§€, null ê¸ˆì§€)
6. reportDateëŠ” ì˜¤ëŠ˜ ë‚ ì§œ (YYYY-MM-DD)
7. ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” í•œêµ­ì–´ ìœ ì§€
8. ìˆœìˆ˜ JSONë§Œ ì¶œë ¥ (ì½”ë“œ ë¸”ë¡ ì—†ì´)

**ì¤‘ìš”**: ì •ë³´ê°€ ë¶€ì¡±í•´ë„ í•©ë¦¬ì ì¸ ì¶”ì •ê°’(ì •ìˆ˜)ê³¼ ìµœì†Œ ê¸¸ì´ë¥¼ ì¶©ì¡±í•˜ëŠ” í…ìŠ¤íŠ¸ë¡œ ì±„ì›Œì•¼ í•©ë‹ˆë‹¤.
"""

    async def _generate_structured_json(self, grounded_facts: str) -> PortfolioReport:
        """
        Step 2: êµ¬ì¡°í™”ëœ JSON ìƒì„± (ìºì‹± ì¶”ê°€)
        
        Args:
            grounded_facts: Step 1ì—ì„œ ìƒì„±ëœ êµ¬ì¡°í™”ëœ ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸
            
        Returns:
            PortfolioReport: Pydantic ê²€ì¦ëœ í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬í¬íŠ¸
            
        Raises:
            ValueError: JSON ìƒì„± ë˜ëŠ” ê²€ì¦ ì‹¤íŒ¨
        """
        # ğŸ†• ìºì‹œ í™•ì¸
        cache_key = self._generate_step2_cache_key(grounded_facts)
        if cache_key in self._cache:
            logger.info("Step 2 ìºì‹œëœ ê²°ê³¼ ë°˜í™˜")
            cached_json = self._cache[cache_key]
            # ìºì‹œëœ JSONì„ PortfolioReportë¡œ ë³€í™˜
            return PortfolioReport.model_validate_json(cached_json)
        
        for attempt in range(self.max_retries):
            try:
                logger.info(
                    f"Step 2: JSON ìƒì„± í˜¸ì¶œ ì‹œë„ {attempt + 1}/{self.max_retries}"
                )
                
                # 1) í”„ë¡¬í”„íŠ¸ ìƒì„± (Step 1 ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ í¬í•¨)
                prompt = self._get_json_generation_prompt(grounded_facts)
                
                # 2) ì„¤ì •: response_mime_typeë§Œ ì‚¬ìš© (response_schemaëŠ” ë³µì¡í•œ Union íƒ€ì… ë¯¸ì§€ì›)
                config = GenerateContentConfig(
                    temperature=0.0,  # ê²°ì •ë¡ ì  ë³€í™˜ì„ ìœ„í•´ ì˜¨ë„ 0
                    max_output_tokens=32768,  # 16384 â†’ 32768ë¡œ ì¦ê°€ (ìµœëŒ€ ì œí•œ)
                    response_mime_type="application/json",  # JSON ëª¨ë“œ
                    # response_schema ë¯¸ì‚¬ìš© - Union[..., dict] íƒ€ì…ì´ additionalProperties ìƒì„±
                    # tools ì—†ìŒ - Google Search Tool ë¹„í™œì„±í™”
                )
                
                # 3) API í˜¸ì¶œ (í…ìŠ¤íŠ¸ë§Œ ì „ë‹¬, ì´ë¯¸ì§€ ì—†ìŒ)
                response = self.client.models.generate_content(
                    model=self.model_name,
                    contents=[prompt],
                    config=config
                )
                
                # 4) JSON í…ìŠ¤íŠ¸ ìˆ˜ë™ íŒŒì‹± (response_schema ë¯¸ì‚¬ìš©)
                if response and getattr(response, "text", None):
                    logger.info("Step 2: JSON ì‘ë‹µ ìˆ˜ì‹ , ìˆ˜ë™ íŒŒì‹± ì‹œì‘")
                    response_text = response.text.strip()
                    
                    try:
                        portfolio_report = PortfolioReport.model_validate_json(response_text)
                        logger.info("Step 2: ìˆ˜ë™ Pydantic ê²€ì¦ ì„±ê³µ")
                        
                        # ğŸ†• ì„±ê³µ ì‹œ ìºì‹œ ì €ì¥ (JSON ë¬¸ìì—´ë¡œ ì €ì¥)
                        portfolio_json = portfolio_report.model_dump_json()
                        self._cache[cache_key] = portfolio_json
                        logger.info(f"Step 2: ìºì‹œ ì €ì¥ ì™„ë£Œ (í‚¤: {cache_key[:16]}...)")
                        
                        return portfolio_report
                    except Exception as validation_error:
                        logger.error(f"Step 2: Pydantic ê²€ì¦ ì‹¤íŒ¨ - {str(validation_error)}")
                        
                        # ê²€ì¦ ì‹¤íŒ¨ ì‹œ 1íšŒ ë³´ì • ì¬ì‹œë„ (ì²« ì‹œë„ì—ì„œë§Œ)
                        if attempt == 0:
                            logger.info("Step 2: ë³´ì • ì¬ì‹œë„ (ëˆ„ë½ í•„ë“œ/ë²”ìœ„ ì˜¤ë¥˜ ìˆ˜ì • ìœ ë„)")
                            await asyncio.sleep(1)
                            continue
                        
                        # JSON ëë¶€ë¶„ í™•ì¸
                        if len(response_text) > 100:
                            logger.error(f"Step 2: JSON ëë¶€ë¶„ (ë§ˆì§€ë§‰ 100ì): {response_text[-100:]}")
                        raise ValueError(
                            f"JSONì´ ìŠ¤í‚¤ë§ˆì™€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {str(validation_error)}"
                        )
                else:
                    raise ValueError("Step 2: Gemini APIì—ì„œ ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                
            except Exception as e:
                logger.error(f"Step 2 í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}): {str(e)}")
                if attempt == self.max_retries - 1:
                    raise ValueError(f"Step 2 JSON ìƒì„± ì‹¤íŒ¨: {str(e)}")
                await asyncio.sleep(2 ** attempt)

    def _get_structured_prompt(self) -> str:
        """êµ¬ì¡°í™”ëœ JSON ì¶œë ¥ìš© í”„ë¡¬í”„íŠ¸ (ìˆœìˆ˜ JSON + íƒœê·¸ ë˜í•‘)"""
        return """
ë‹¹ì‹ ì€ ì „ë¬¸ í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì œê³µëœ í¬íŠ¸í´ë¦¬ì˜¤ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•˜ëŠ” "ìˆœìˆ˜ JSON"ë§Œ ìƒì„±í•˜ì„¸ìš”.

ì¤‘ìš” ê·œì¹™:
1) JSON ì™¸ ì–´ë– í•œ í…ìŠ¤íŠ¸/ì£¼ì„/ì„¤ëª…/ì½”ë“œë¸”ë¡ë„ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”
2) JSONì€ ë°˜ë“œì‹œ <JSON_START> ì™€ <JSON_END> íƒœê·¸ë¡œ ê°ì‹¸ì„œ ì¶œë ¥í•˜ì„¸ìš”
3) ëª¨ë“  ì ìˆ˜ëŠ” 0-100 ì‚¬ì´ì˜ ì •ìˆ˜ê°’ìœ¼ë¡œ ì±„ì›Œ ë„£ê³ , ë²”ìœ„ í‘œê¸°(ì˜ˆ: 0-100)ëŠ” ì ˆëŒ€ ì“°ì§€ ë§ˆì„¸ìš”
4) reportDateëŠ” ì˜¤ëŠ˜ ë‚ ì§œ(YYYY-MM-DD)
5) tabsëŠ” ì •í™•íˆ 4ê°œ: dashboard, deepDive, allStockScores, keyStockAnalysis

ì¶œë ¥ JSON ì˜ˆì‹œ êµ¬ì¡° (ê°’ì€ ì‹¤ì œ ë¶„ì„ìœ¼ë¡œ ì±„ìš°ì„¸ìš”):
{
  "version": "1.0",
  "reportDate": "2025-09-30",
  "tabs": [
    {
      "tabId": "dashboard",
      "tabTitle": "ì´ê´„ ìš”ì•½",
      "content": {
        "overallScore": {"title": "í¬íŠ¸í´ë¦¬ì˜¤ ì¢…í•© ìŠ¤ì½”ì–´", "score": 72, "maxScore": 100},
        "coreCriteriaScores": [
          {"criterion": "ì„±ì¥ ì ì¬ë ¥", "score": 88, "maxScore": 100},
          {"criterion": "ì•ˆì •ì„± ë° ë°©ì–´ë ¥", "score": 55, "maxScore": 100},
          {"criterion": "ì „ëµì  ì¼ê´€ì„±", "score": 74, "maxScore": 100}
        ],
        "strengths": ["ê°•ì 1", "ê°•ì 2"],
        "weaknesses": ["ì•½ì 1", "ì•½ì 2"]
      }
    },
    {
      "tabId": "deepDive",
      "tabTitle": "í¬íŠ¸í´ë¦¬ì˜¤ ì‹¬ì¸µ ë¶„ì„",
      "content": {
        "inDepthAnalysis": [
          {"title": "ì„±ì¥ ì ì¬ë ¥", "score": 85, "description": "ìµœì†Œ 50ì ìƒì„¸ ë¶„ì„"},
          {"title": "ì•ˆì •ì„± ë° ë°©ì–´ë ¥", "score": 70, "description": "ìµœì†Œ 50ì ìƒì„¸ ë¶„ì„"},
          {"title": "ì „ëµì  ì¼ê´€ì„±", "score": 80, "description": "ìµœì†Œ 50ì ìƒì„¸ ë¶„ì„"}
        ],
        "opportunities": {
          "title": "ê¸°íšŒ ë° ê°œì„  ë°©ì•ˆ",
          "items": [{"summary": "ìš”ì•½", "details": "ìµœì†Œ 30ì ìƒì„¸ ì„¤ëª… (What-if í¬í•¨)"}]
        }
      }
    },
    {
      "tabId": "allStockScores",
      "tabTitle": "ê°œë³„ ì¢…ëª© ìŠ¤ì½”ì–´",
      "content": {
        "scoreTable": {
          "headers": ["ì£¼ì‹", "Overall", "í€ë”ë©˜íƒˆ", "ê¸°ìˆ  ì ì¬ë ¥", "ê±°ì‹œê²½ì œ", "ì‹œì¥ì‹¬ë¦¬", "CEO/ë¦¬ë”ì‹­"],
          "rows": [
            {"ì£¼ì‹": "ì¢…ëª©ëª…", "Overall": 80, "í€ë”ë©˜íƒˆ": 75, "ê¸°ìˆ  ì ì¬ë ¥": 82, "ê±°ì‹œê²½ì œ": 78, "ì‹œì¥ì‹¬ë¦¬": 84, "CEO/ë¦¬ë”ì‹­": 80}
          ]
        }
      }
    },
    {
      "tabId": "keyStockAnalysis",
      "tabTitle": "í•µì‹¬ ì¢…ëª© ìƒì„¸ ë¶„ì„",
      "content": {
        "analysisCards": [
          {
            "stockName": "ì¢…ëª©ëª…",
            "overallScore": 82,
            "detailedScores": [
              {"category": "í€ë”ë©˜íƒˆ", "score": 80, "analysis": "ìµœì†Œ 30ì ë¶„ì„"},
              {"category": "ê¸°ìˆ  ì ì¬ë ¥", "score": 85, "analysis": "ìµœì†Œ 30ì ë¶„ì„"},
              {"category": "ê±°ì‹œê²½ì œ", "score": 78, "analysis": "ìµœì†Œ 30ì ë¶„ì„"},
              {"category": "ì‹œì¥ì‹¬ë¦¬", "score": 84, "analysis": "ìµœì†Œ 30ì ë¶„ì„"},
              {"category": "CEO/ë¦¬ë”ì‹­", "score": 80, "analysis": "ìµœì†Œ 30ì ë¶„ì„"}
            ]
          }
        ]
      }
    }
  ]
}

ìœ„ JSONë§Œì„ ë‹¤ìŒê³¼ ê°™ì´ ì¶œë ¥:
<JSON_START>
{...ì—¬ê¸°ì— ìˆœìˆ˜ JSONë§Œ...}
</JSON_END>
"""

    async def _call_gemini_structured(self, image_data_list: List[bytes]) -> PortfolioReport:
        """Gemini API êµ¬ì¡°í™”ëœ ì¶œë ¥ í˜¸ì¶œ (JSON ëª¨ë“œ: ì„œë²„ì—ì„œ Pydantic ê²€ì¦)"""
        for attempt in range(self.max_retries):
            try:
                logger.info(
                    f"Gemini API êµ¬ì¡°í™”ëœ ì¶œë ¥ í˜¸ì¶œ ì‹œë„ {attempt + 1}/{self.max_retries}"
                )

                contents: List[Union[str, Part]] = []
                # 1) ì´ë¯¸ì§€ íŒŒíŠ¸
                for i, image_data in enumerate(image_data_list):
                    image_part = Part.from_bytes(data=image_data, mime_type="image/jpeg")
                    contents.append(image_part)
                    logger.debug(f"êµ¬ì¡°í™”: ì´ë¯¸ì§€ {i+1}/{len(image_data_list)} ì¶”ê°€")
                # 2) í”„ë¡¬í”„íŠ¸
                contents.append(self._get_structured_prompt())

                # 3) Google Search ë„êµ¬
                from google.genai import types
                grounding_tool = types.Tool(google_search=types.GoogleSearch())

                # 4) ì„¤ì •: ë„êµ¬ ì‚¬ìš© ìœ ì§€, MIME íƒ€ì… ê°•ì œ ì§€ì • ì œê±° (ë„êµ¬ì™€ ë™ì‹œ ì‚¬ìš© ì‹œ ì œì•½ íšŒí”¼)
                config = GenerateContentConfig(
                    temperature=0.1,
                    max_output_tokens=32768,  # 16384 â†’ 32768ë¡œ ì¦ê°€ (ìµœëŒ€ ì œí•œ)
                    tools=[grounding_tool],
                )

                # 5) API í˜¸ì¶œ
                response = self.client.models.generate_content(
                    model=self.model_name, contents=contents, config=config
                )

                # 6) JSON í…ìŠ¤íŠ¸ íŒŒì‹± ë° Pydantic ê²€ì¦
                if response and getattr(response, "text", None):
                    logger.info("Gemini API ì‘ë‹µ ìˆ˜ì‹ , JSON ì¶”ì¶œ ë° Pydantic ê²€ì¦ ì‹œì‘")
                    
                    # ì‘ë‹µì—ì„œ JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (<JSON_START>..<JSON_END> ë˜ëŠ” ì½”ë“œë¸”ë¡/ë¸Œë ˆì´ìŠ¤ ë§¤ì¹­)
                    response_text = response.text.strip()
                    
                    # 1) íƒœê·¸ ê¸°ë°˜ ì¶”ì¶œ
                    if "<JSON_START>" in response_text and "<JSON_END>" in response_text:
                        start = response_text.find("<JSON_START>") + len("<JSON_START>")
                        end = response_text.find("<JSON_END>")
                        response_text = response_text[start:end].strip()
                    else:
                        # 2) ì½”ë“œë¸”ë¡ ì œê±°
                        if response_text.startswith("```json"):
                            response_text = response_text[7:]
                        if response_text.startswith("```"):
                            response_text = response_text[3:]
                        if response_text.endswith("```"):
                            response_text = response_text[:-3]
                        response_text = response_text.strip()
                        # 3) ë¸Œë ˆì´ìŠ¤ ë§¤ì¹­ìœ¼ë¡œ ì²« JSON ê°ì²´ ì¶”ì¶œ
                        first_brace = response_text.find('{')
                        last_brace = response_text.rfind('}')
                        if first_brace != -1 and last_brace != -1 and last_brace > first_brace:
                            response_text = response_text[first_brace:last_brace+1]
                    
                    try:
                        portfolio_report = PortfolioReport.model_validate_json(response_text)
                        logger.info("PortfolioReport ê²€ì¦ ì„±ê³µ")
                        return portfolio_report
                    except Exception as validation_error:
                        logger.error(f"Pydantic ê²€ì¦ ì‹¤íŒ¨: {str(validation_error)}")
                        # ì‘ë‹µ ì¼ë¶€ ë¡œê¹… (ê³¼ë„í•œ ë¡œê·¸ ë°©ì§€)
                        preview = response_text[:500] if isinstance(response_text, str) else str(response_text)[:500]
                        logger.debug(f"ì‘ë‹µ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {preview}...")
                        raise ValueError(
                            f"Gemini ì‘ë‹µì´ ìŠ¤í‚¤ë§ˆì™€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {str(validation_error)}"
                        )

                raise ValueError("Gemini APIì—ì„œ JSON ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

            except Exception as e:
                logger.error(f"êµ¬ì¡°í™”ëœ ì¶œë ¥ í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}): {str(e)}")
                if attempt == self.max_retries - 1:
                    raise
                await asyncio.sleep(2 ** attempt)

    async def analyze_portfolio_structured(
        self, image_data_list: List[bytes], format_type: str = "json"
    ) -> Union[StructuredAnalysisResponse, AnalysisResponse]:
        """
        í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ - formatì— ë”°ë¼ JSON ë˜ëŠ” ë§ˆí¬ë‹¤ìš´ ë°˜í™˜
        JSON ëª¨ë“œ ì‹œ Two-step ì „ëµ ì‚¬ìš©: ê²€ìƒ‰Â·ê·¸ë¼ìš´ë”© â†’ êµ¬ì¡°í™” JSON
        """
        start_time = time.time()
        request_id = str(uuid.uuid4())

        # ì…ë ¥ ê²€ì¦
        if not image_data_list or len(image_data_list) == 0:
            raise ValueError("ë¶„ì„í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        if len(image_data_list) > 5:
            raise ValueError("ìµœëŒ€ 5ê°œì˜ ì´ë¯¸ì§€ë§Œ ë¶„ì„ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        for i, image_data in enumerate(image_data_list):
            await validate_image(image_data)

        if format_type == "json":
            try:
                logger.info("=== Two-step JSON ìƒì„± ì‹œì‘ ===")
                
                # Step 1: ê²€ìƒ‰Â·ê·¸ë¼ìš´ë”© (Google Search Tool ì‚¬ìš©)
                logger.info("Step 1: ê²€ìƒ‰Â·ê·¸ë¼ìš´ë”© í˜¸ì¶œ")
                grounded_facts = await self._generate_grounded_facts(image_data_list)
                logger.info(f"Step 1 ì™„ë£Œ - êµ¬ì¡°í™”ëœ ë°ì´í„° ê¸¸ì´: {len(grounded_facts)}ì")
                
                # Step 2: êµ¬ì¡°í™”ëœ JSON ìƒì„± (Step 1 ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ)
                logger.info("Step 2: JSON ìŠ¤í‚¤ë§ˆ ìƒì„± í˜¸ì¶œ")
                portfolio_report = await self._generate_structured_json(grounded_facts)
                logger.info("Step 2 ì™„ë£Œ - Pydantic ê²€ì¦ ì„±ê³µ")
                
                logger.info("=== Two-step JSON ìƒì„± ì™„ë£Œ ===")
                
            except ValueError as ve:
                # Step 1 ë˜ëŠ” Step 2 ì‹¤íŒ¨ ì‹œ ì‚¬ìš©ì ì¹œí™”ì  ì—ëŸ¬
                logger.error(f"Two-step JSON ìƒì„± ì‹¤íŒ¨: {str(ve)}")
                raise ValueError("AI ì‘ë‹µì´ ì˜ˆìƒ í˜•ì‹ê³¼ ë‹¤ë¦…ë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
            
            return StructuredAnalysisResponse(
                portfolioReport=portfolio_report,
                processing_time=time.time() - start_time,
                request_id=request_id,
                images_processed=len(image_data_list),
            )
        else:
            # ê¸°ì¡´ ë§ˆí¬ë‹¤ìš´ ì¶œë ¥ ì¬ì‚¬ìš© (ë³€ê²½ ì—†ìŒ)
            if len(image_data_list) == 1:
                markdown_content = await self.analyze_portfolio_image(
                    image_data_list[0], use_cache=True
                )
            else:
                markdown_content = await self.analyze_multiple_portfolio_images(
                    image_data_list
                )
            return AnalysisResponse(
                content=markdown_content,
                processing_time=time.time() - start_time,
                request_id=request_id,
                images_processed=len(image_data_list),
            )

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_gemini_service: Optional[GeminiService] = None

async def get_gemini_service() -> GeminiService:
    """GeminiService ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _gemini_service
    if _gemini_service is None:
        _gemini_service = GeminiService()
    return _gemini_service
